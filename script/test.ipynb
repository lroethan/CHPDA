{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_frequencies = [1265, 897, 643, 1190, 521, 1688, 778, 1999, 1690, 1433, 1796, 1266, 1046, 1353]\n",
    "frequencies = np.array(_frequencies) / np.array(_frequencies).sum()\n",
    "\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TiDBHypo(\"imdbload\")\n",
    "# b = a.execute_create_hypo(\"aka_name#surname_pcode\")\n",
    "b = a.get_hypo_indexes_from_one_table(\"aka_name\")\n",
    "b\n",
    "# a.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "string = \"KEY `hypo_aka_name_name_pcode_nf_idx` (`name_pcode_nf`) /* HYPO INDEX */\"\n",
    "\n",
    "if \"HYPO INDEX\" in string:\n",
    "    tmp = string.split(\"`\")\n",
    "    idx_name = tmp[1]\n",
    "    table_name = \"aka_name\"\n",
    "    hypo = f\"{table_name}.{idx_name}\"\n",
    "    print(hypo)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.zeros(60, dtype=np.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "\n",
    "def get_hypo_indexes_from_table(conn, table_name):\n",
    "    statement = f\"show create table {table_name}\"\n",
    "    cur = conn.cursor()\n",
    "    result = cur.execute(statement)\n",
    "    hypo_indexes = []\n",
    "    for line in result[1].split(\"\\n\"):\n",
    "        if \"HYPO INDEX\" in line:\n",
    "            tmp = line.split(\"`\")\n",
    "            hypo_indexes.append(tmp[1])\n",
    "    return hypo_indexes\n",
    "    \n",
    "    \n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1',\n",
    "                     port=4000,\n",
    "                     user='root',\n",
    "                     password='',\n",
    "                     database=\"imdbload\",\n",
    "                     local_infile=True)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "statement = \"create index hypo_aka_name_name_pcode_nf_idx type hypo on aka_name (name_pcode_nf);\"\n",
    "s2 = \"show create table aka_name;\"\n",
    "\n",
    "\n",
    "cur.execute(statement)\n",
    "\n",
    "print(get_hypo_indexes_from_table(conn, \"aka_name\"))\n",
    "\n",
    "cur.execute(s2)\n",
    "\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [1.0, 0.0, 1.0]\n",
    "index_candidates=[\"123\",\"423123\", \"23123\"]\n",
    "\n",
    "selected_indexes = [index_candidates[i] for i, idx in enumerate(indexes) if idx == 1.0]\n",
    "\n",
    "selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "action = np.random.randint(0, 65)\n",
    "\n",
    "\n",
    "\n",
    "a = np.float64(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['customer#c_custkey,c_mktsegment', 'lineitem#l_commitdate,l_receiptdate', 'lineitem#l_orderkey,l_receiptdate', 'lineitem#l_orderkey,l_shipdate', 'lineitem#l_partkey', 'lineitem#l_partkey,l_quantity,l_extendedprice', 'lineitem#l_partkey,l_shipdate', 'lineitem#l_partkey,l_suppkey', 'lineitem#l_partkey,l_suppkey,l_shipdate', 'lineitem#l_receiptdate', 'lineitem#l_returnflag', 'lineitem#l_shipdate', 'lineitem#l_shipmode', 'lineitem#l_suppkey', 'lineitem#l_suppkey,l_partkey', 'lineitem#l_suppkey,l_partkey,l_shipdate', 'nation#n_name', 'nation#n_name,n_nationkey', 'nation#n_nationkey', 'nation#n_nationkey,n_name', 'nation#n_regionkey', 'orders#o_custkey', 'orders#o_custkey,o_orderdate', 'orders#o_orderkey', 'orders#o_orderkey,o_orderdate', 'orders#o_orderkey,o_orderdate,o_custkey', 'orders#o_orderkey,o_orderstatus', 'orders#o_orderstatus,o_orderkey', 'part#p_brand', 'part#p_brand,p_container,p_partkey', 'part#p_brand,p_partkey', 'part#p_brand,p_partkey,p_container', 'part#p_container,p_brand', 'part#p_container,p_brand,p_partkey', 'part#p_container,p_partkey', 'part#p_container,p_partkey,p_brand', 'part#p_partkey,p_brand,p_container', 'part#p_partkey,p_container', 'part#p_partkey,p_container,p_brand', 'part#p_partkey,p_type', 'partsupp#ps_availqty', 'partsupp#ps_partkey', 'partsupp#ps_partkey,ps_availqty,ps_suppkey', 'partsupp#ps_partkey,ps_suppkey', 'partsupp#ps_partkey,ps_suppkey,ps_availqty', 'partsupp#ps_suppkey', 'partsupp#ps_suppkey,ps_availqty,ps_partkey', 'partsupp#ps_suppkey,ps_partkey', 'partsupp#ps_suppkey,ps_partkey,ps_availqty', 'region#r_name', 'region#r_name,r_regionkey', 'region#r_regionkey,r_name']\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取../entry/cands.pickle打印成数组，并输出长度\n",
    "import pickle\n",
    "\n",
    "def count_distinct_prefix(strings):\n",
    "    distinct_prefixes = set()\n",
    "    for string in strings:\n",
    "        prefix = string.split('#')[0]\n",
    "        distinct_prefixes.add(prefix)\n",
    "    return distinct_prefixes\n",
    "\n",
    "with open(\"../entry/cands.pickle\", \"rb\") as f:\n",
    "    cands = pickle.load(f)\n",
    "    add = list(count_distinct_prefix(cands))\n",
    "    add_with_prefix = [f\"{prefix}#tiflash\" for prefix in add]\n",
    "    print(add_with_prefix)\n",
    "    cands.extend(add_with_prefix)\n",
    "    with open('../entry/cands2.pickle', 'wb') as file:\n",
    "        pickle.dump(cands, file)\n",
    "    # cands.append(\"customer#tiflash\")\n",
    "    # print(len(cands))\n",
    "print(len(cands))\n",
    "print(cands)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../entry/workload.pickle\", \"rb\") as f:\n",
    "    workload = pickle.load(f)\n",
    "    print(workload)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPC-DS 的手工候选索引集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "candidate_hand = [\n",
    "    \"store_sales#ss_item_sk,ss_sold_date_sk,ss_ext_sales_price\",\n",
    "    \"item#i_item_sk,i_category,i_class,i_item_id,i_item_desc\",\n",
    "    \"date_dim#d_date_sk\",\n",
    "    \"inventory#inv_item_sk,inv_warehouse_sk,inv_date_sk\",\n",
    "    \"warehouse#w_warehouse_sk\",\n",
    "    \"item#i_current_price,i_item_sk\",\n",
    "    \"date_dim#d_date_sk\",\n",
    "    \"customer_address#ca_address_sk\",\n",
    "    \"customer#c_current_addr_sk,c_customer_sk\",\n",
    "    \"store_sales#ss_customer_sk,ss_sold_date_sk,ss_item_sk\",\n",
    "    \"date_dim#d_date_sk,d_month_seq,d_year,d_moy\",\n",
    "    \"item#i_item_sk,i_current_price,i_category\",\n",
    "    \"web_sales#ws_item_sk,ws_sold_date_sk,ws_ext_sales_price\",\n",
    "    \"item#i_item_sk,i_category,i_class,i_item_id,i_item_desc\",\n",
    "    \"date_dim#d_date_sk\",\n",
    "    \"web_sales#ws_web_page_sk,ws_item_sk,ws_order_number,ws_sold_date_sk,ws_sales_price,ws_net_profit\",\n",
    "    \"web_returns#wr_item_sk,wr_order_number,wr_reason_sk,wr_refunded_cdemo_sk,wr_returning_cdemo_sk,wr_refunded_addr_sk,wr_refunded_cash,wr_fee\",\n",
    "    \"web_page#wp_web_page_sk\",\n",
    "    \"customer_demographics#cd_demo_sk,cd_marital_status,cd_education_status\",\n",
    "    \"customer_address#ca_address_sk,ca_country,ca_state\",\n",
    "    \"date_dim#d_date_sk,d_year\",\n",
    "    \"reason#r_reason_sk\",\n",
    "    \"web_sales#ws_item_sk,ws_order_number,ws_sold_date_sk,ws_quantity,ws_net_paid,ws_net_profit\",\n",
    "    \"web_returns#wr_order_number,wr_item_sk,wr_return_quantity,wr_return_amt\",\n",
    "    \"date_dim#d_date_sk,d_year,d_moy\",\n",
    "    \"catalog_sales#cs_order_number,cs_item_sk,cs_quantity,cs_net_paid,cs_net_profit\",\n",
    "    \"catalog_returns#cr_order_number,cr_item_sk,cr_return_quantity,cr_return_amount\",\n",
    "    \"store_sales#ss_ticket_number,ss_item_sk,ss_quantity,ss_net_paid,ss_net_profit\",\n",
    "    \"store_returns#sr_ticket_number,sr_item_sk,sr_return_quantity,sr_return_amt\",\n",
    "    \"date_dim#d_date_sk,d_year,d_moy\",\n",
    "    \"store_sales#ss_sold_date_sk,ss_item_sk,ss_ext_sales_price\",\n",
    "    \"item#i_item_sk,i_brand_id,i_brand,i_manager_id\",\n",
    "    \"web_sales#ws_item_sk,ws_sold_date_sk,ws_ext_discount_amt\",\n",
    "    \"item#i_manufact_id,i_item_sk\",\n",
    "    \"date_dim#d_date,d_date_sk\"\n",
    "]\n",
    "\n",
    "candidate_hand = list(set(candidate_hand))\n",
    "\n",
    "# add = ['call_center#tiflash', 'catalog_page#tiflash', 'catalog_returns#tiflash', 'catalog_sales#tiflash', 'customer#tiflash', 'customer_address#tiflash', 'customer_demographics#tiflash', 'date_dim#tiflash', 'dbgen_version#tiflash', 'household_demographics#tiflash', 'income_band#tiflash', 'inventory#tiflash', 'item#tiflash', 'promotion#tiflash', 'reason#tiflash', 'ship_mode#tiflash', 'store#tiflash', 'store_returns#tiflash', 'store_sales#tiflash', 'time_dim#tiflash', 'warehouse#tiflash', 'web_page#tiflash', 'web_returns#tiflash', 'web_sales#tiflash', 'web_site#tiflash']\n",
    "\n",
    "# candidate_hand.extend(add)\n",
    "\n",
    "with open(\"../entry/hand_cands.pickle\", \"wb\") as f:\n",
    "    pickle.dump(candidate_hand, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../workload/tpcds/queries.sql\"\n",
    "queries = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    query = \"\"\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.startswith('--') or not line:\n",
    "            continue  # 跳过注释行和空行\n",
    "        if line.endswith(';'):\n",
    "            query += line\n",
    "            queries.append(query)\n",
    "            query = \"\"\n",
    "        else:\n",
    "            query += line + \" \"\n",
    "\n",
    "# 打印标记后的SQL语句\n",
    "for i, query in enumerate(queries, start=1):\n",
    "    print(f\"Query {i}: {query}\")\n",
    "\n",
    "\n",
    "with open(\"../entry/tpcds.pickle\", \"wb\") as f:\n",
    "    pickle.dump(queries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"hypo_store_sales_ss_item_sk_ss_sold_date_sk_ss_ext_sales_price_idx\"\n",
    "\n",
    "a[:50]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
